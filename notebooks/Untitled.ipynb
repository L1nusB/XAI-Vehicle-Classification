{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6293ab3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing BlurSegments step into Pipeline\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import mmcv\n",
    "import importlib\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from mmcv import Config\n",
    "from mmcls.datasets.pipelines import Compose\n",
    "from mmcls.models.builder import build_classifier\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib import cm\n",
    "from PIL import Image\n",
    "import heapq\n",
    "from mmseg.apis import inference_segmentor, init_segmentor\n",
    "from mmseg.core.evaluation import get_palette\n",
    "from mmseg.datasets.builder import build_dataset, build_dataloader, DATASETS\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "import cv2\n",
    "import pandas\n",
    "import json\n",
    "import seaborn as sns\n",
    "\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "\n",
    "from scripts import generate_statistics_single\n",
    "from scripts import visualization_seg_masks\n",
    "from scripts import generate_statistics\n",
    "from scripts import generate_cams\n",
    "from scripts import utils\n",
    "from scripts.utils.pipeline import get_pipeline_torchvision\n",
    "from scripts import generate_segs\n",
    "from scripts import visualize_cam_results\n",
    "from scripts.utils.BlurDataset import get_blurred_dataset\n",
    "from scripts.utils import preprocessing, io\n",
    "from scripts.utils.model import get_wrongly_classified\n",
    "from scripts.utils.evaluation import compare_original_blurred, get_eval_metrics\n",
    "from scripts import evaluate_effectiveness\n",
    "from scripts.generate_blurred import generate_blurred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90766d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "configSeg = '../segmentation/ocrnet_hr48_512x512_carparts_noflip/ocrnet_hr48_512x512_carparts_noflip.py'\n",
    "checkpointSeg = '../segmentation/ocrnet_hr48_512x512_carparts_noflip/latest.pth'\n",
    "\n",
    "segDataPathOriginal = 'G:/XAI-Vehicle-Classification/preGenData/Segmentations/CompCars_Original/valAllSegs.npz'\n",
    "segDataPathColor = 'G:/XAI-Vehicle-Classification/preGenData/Segmentations/CompCars_Color/valAllSegs.npz'\n",
    "segDataPathWeb = 'G:/XAI-Vehicle-Classification/preGenData/Segmentations/CompCars_Web/valAllSegs.npz'\n",
    "segDataPathStanford = 'G:/XAI-Vehicle-Classification/preGenData/Segmentations/StanfordCars_Original/valAllSegs.npz'\n",
    "\n",
    "paletteName='Comp_Original_Ocrnet_Carparts_Noflip'\n",
    "\n",
    "segDataPathOG = 'G:/XAI-Vehicle-Classification/preGenData/Segmentations/CompCars_Original/valAllSegs.npz'\n",
    "segDataPathNoScaleOG = 'G:/XAI-Vehicle-Classification/preGenData/Segmentations/CompCars_Original/valAllSegsNoScale.npz'\n",
    "segDataPathNoScaleWeb = 'G:/XAI-Vehicle-Classification/preGenData/Segmentations/CompCars_Web/valAllSegsNoScale.npz'\n",
    "segDataPathNoScaleStanford = 'G:/XAI-Vehicle-Classification/preGenData/Segmentations/StanfordCars_Original/valAllSegsNoScale.npz'\n",
    "\n",
    "camDataGradCAM = 'G:/XAI-Vehicle-Classification/preGenData/CompCars_original/ResNet/valAllCAMs.npz'\n",
    "camDataEigenCAM = 'G:/XAI-Vehicle-Classification/preGenData/CompCars_original/ResNet/valAllCAMsEigen.npz'\n",
    "camDataEigenGrad = 'G:/XAI-Vehicle-Classification/preGenData/CompCars_original/ResNet/valAllCAMsEigenGrad.npz'\n",
    "camDataGradCAMGPU = 'G:/XAI-Vehicle-Classification/preGenData/CompCars_original/ResNet/valAllCAMsGPU.npz'\n",
    "camDataGradCAMPlusPlus = 'G:/XAI-Vehicle-Classification/preGenData/CompCars_original/ResNet/valAllCAMsGrad++.npz'\n",
    "camDataLayerCAM = 'G:/XAI-Vehicle-Classification/preGenData/CompCars_original/ResNet/valAllCAMsLayer.npz'\n",
    "camDataXCAM = 'G:/XAI-Vehicle-Classification/preGenData/CompCars_original/ResNet/valAllCAMsXGrad.npz'\n",
    "\n",
    "imgRootValOriginal = '../data/CompCars_sv_original_split/val'\n",
    "imgRootValColor = '../data/CompCars_sv_color_split/val'\n",
    "imgRootValWeb = '../data/CompCars_web_original_split/val'\n",
    "imgRootValStandford = '../data/StanfordCars_original_split/val'\n",
    "\n",
    "annfileValOriginal = '../data/CompCars_sv_original_split/meta/val.txt'\n",
    "annfileValColor = '../data/CompCars_sv_color_split/meta/val.txt'\n",
    "annfileValWeb = '../data/CompCars_web_original_split/meta/val.txt'\n",
    "annfileValStanford = '../data/StanfordCars_original_split/meta/val.txt'\n",
    "\n",
    "annfileValWebShareOriginal = '../data/CompCars_web_original_split/meta/annfile_shared_original.txt'\n",
    "\n",
    "dirResOG = 'G:/results/CompCars_original/ResNet'\n",
    "dirResCol = 'G:/results/CompCars_Color/ResNet'\n",
    "dirResWeb = 'G:/results/CompCars_Web/ResNet'\n",
    "\n",
    "dirSwinBaseOG = 'G:/results/CompCars_original/SwinBase'\n",
    "dirSwinBaseCol = 'G:/results/CompCars_Color/SwinBase'\n",
    "dirSwinBaseWeb = 'G:/results/CompCars_Web/SwinBase'\n",
    "\n",
    "dirSwinSmallOG = 'G:/results/CompCars_original/SwinSmall'\n",
    "dirSwinSmallCol = 'G:/results/CompCars_Color/SwinSmall'\n",
    "dirSwinSmallWeb = 'G:/results/CompCars_Web/SwinSmall'\n",
    "\n",
    "configCAMResOriginal = '../CAMModels/resnet/compCars_Original/resnet50_b128x2_compcars-original-split.py'\n",
    "checkpointCAMResOriginal = '../CAMModels/resnet/compCars_Original/latest.pth'\n",
    "configCAMResColor = '../CAMModels/resnet/compCars_Color/resnet50_b128x2_compcars-color-split.py'\n",
    "checkpointCAMResColor = '../CAMModels/resnet/compCars_Color/latest.pth'\n",
    "configCAMResWeb = '../CAMModels/resnet/compCars_Web/resnet50_b128x2_compcars-web-original-split.py'\n",
    "checkpointCAMResWeb = '../CAMModels/resnet/compCars_Web/latest.pth'\n",
    "configCAMResStanford = '../CAMModels/resnet/stanfordCars_Original/resnet50_b128x2_stanford.py'\n",
    "checkpointCAMResStanford = '../CAMModels/resnet/stanfordCars_Original/latest.pth'\n",
    "\n",
    "configCAMSwinBaseOriginal = '../CAMModels/swinBase/compCars_Original/swin-base_b128x2_compcars-original-split.py'\n",
    "checkpointCAMSwinBaseOriginal = '../CAMModels/swinBase/compCars_Original/latest.pth'\n",
    "configCAMSwinBaseColor = '../CAMModels/swinBase/compCars_Color/swin-base_b128x2_compcars-color-split.py'\n",
    "checkpointCAMSwinBaseColor = '../CAMModels/swinBase/compCars_Color/latest.pth'\n",
    "configCAMSwinBaseWeb = '../CAMModels/swinBase/compCars_Web/swin-base_b128x2_compcars-web-original-split.py'\n",
    "checkpointCAMSwinBaseWeb = '../CAMModels/swinBase/compCars_Web/latest.pth'\n",
    "configCAMSwinBaseStanford = '../CAMModels/swinBase/stanfordCars_Original/swin-base_b128x2_stanford.py'\n",
    "checkpointCAMSwinBaseStanford = '../CAMModels/swinBase/stanfordCars_Original/latest.pth'\n",
    "\n",
    "configCAMSwinSmallOriginal = '../CAMModels/swinSmall/compCars_Original/swin-small_b128x2_compcars-original-split.py'\n",
    "checkpointCAMSwinSmallOriginal = '../CAMModels/swinSmall/compCars_Original/latest.pth'\n",
    "configCAMSwinSmallColor = '../CAMModels/swinSmall/compCars_Color/swin-small_b128x2_compcars-color-split.py'\n",
    "checkpointCAMSwinSmallColor = '../CAMModels/swinSmall/compCars_Color/latest.pth'\n",
    "configCAMSwinSmallWeb = '../CAMModels/swinSmall/compCars_Web/swin-small_b128x2_compcars-web-original-split.py'\n",
    "checkpointCAMSwinSmallWeb = '../CAMModels/swinSmall/compCars_Web/latest.pth'\n",
    "configCAMSwinSmallStanford = '../CAMModels/swinSmall/stanfordCars_Original/swin-small_b128x2_stanford.py'\n",
    "checkpointCAMSwinSmallStanford = '../CAMModels/swinSmall/stanfordCars_Original/latest.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7337cc8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating original model vs blurred background.\n",
      "Evaluating original model vs blurred where segments background are blurred.\n",
      "Created filtered annotation file at compareResults/newLoad\\annfile_filtered.txt\n",
      "Using standard dataset on blurred data at directory ../data/CompCars_sv_original_split/blurred/blurredBackground\n",
      "Model already on GPU\n",
      "Using given evaluation data of original model.\n",
      "Loading data from Json ./eval_results_original.json\n",
      "Computing Evaluation Metrics for Blurred Dataset\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>] 13333/13333, 267.7 task/s, elapsed: 50s, ETA:     0s\n",
      "Saving json data to compareResults/newLoad\\eval_results_blurred.json\n",
      "Add total Change and improvement of original over blurred\n",
      "Saving evaluation results to compareResults/newLoad\\evalBlurred.xlsx\n",
      "Removing temporary filtered annotation file compareResults/newLoad\\annfile_filtered.txt\n"
     ]
    }
   ],
   "source": [
    "imgRootBlurredBackground = '../data/CompCars_sv_original_split/blurred/blurredBackground'\n",
    "evaluate_effectiveness.evaluate_blurred_background(imgRoot=imgRootValOriginal, classifierConfig=configCAMResOG, \n",
    "                                                   classifierCheckpoint=checkpointCAMResOG, annfile=annfileValOriginal,\n",
    "                                                   segData=segDataPathNoScaleOG, segConfig=configSeg, saveImgs=False,\n",
    "                                                   segCheckpoint=checkpointSeg,  saveDir='compareResults/newLoad',\n",
    "                                                   eval_data_original='./eval_results_original.json',\n",
    "                                                   imgRootBlurred=imgRootBlurredBackground)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6773c8e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating original model vs blurred relative Importance with top 3 blurred.\n",
      "Blurring 3 segments out of 19.\n",
      "Blurring segment with index 10,13,16\n",
      "Blurring segments front_left_light,hood,tailgate\n",
      "Evaluating original model vs blurred where segments [10, 13, 16] are blurred.\n",
      "Created filtered annotation file at pipeline\\annfile_filtered.txt\n",
      "Computing blurred images on demand.\n",
      "Blurred Images will be saved to pipeline\\blurredImgs\n",
      "Model already on GPU\n",
      "Using given evaluation data of original model.\n",
      "Loading data from Json ./eval_results_original.json\n",
      "Computing Evaluation Metrics for Blurred Dataset\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>] 13333/13333, 19.5 task/s, elapsed: 682s, ETA:     0s\n",
      "Saving json data to pipeline\\eval_results_blurred.json\n",
      "Add total Change and improvement of original over blurred\n",
      "Saving evaluation results to pipeline\\evalBlurred.xlsx\n",
      "Removing temporary filtered annotation file pipeline\\annfile_filtered.txt\n"
     ]
    }
   ],
   "source": [
    "resultsFile = os.path.join(dirResOG, 'normalized', \n",
    "                           'Data_Full_gradCAM_ResNet_CompCars_Original_ocrnet_hr48_carparts_noflip_normalized_PropArea_23_08_2022.xlsx')\n",
    "\n",
    "evaluate_effectiveness.evaluate_blurred_rel_importance(imgRoot=imgRootValOriginal, classifierConfig=configCAMResOG,\n",
    "                                                      classifierCheckpoint=checkpointCAMResOG, annfile=annfileValOriginal,\n",
    "                                                      segData=segDataPathNoScaleOG, importanceScoreFile=resultsFile, \n",
    "                                                      saveImgs=True, saveDir='pipeline', randomBlur=False,\n",
    "                                                      eval_data_original='./eval_results_original.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "395807e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating original model vs blurred where segments ['front_bumper', 'hood', 'background'] are blurred.\n",
      "Created filtered annotation file at background_hood_fbumper\\annfile_filtered.txt\n",
      "Computing blurred images on demand.\n",
      "Blurred Images will be saved to background_hood_fbumper\\blurredImgs\n",
      "Model already on GPU\n",
      "Using given evaluation data of original model.\n",
      "Loading data from Json ./eval_results_original.json\n",
      "Computing Evaluation Metrics for Blurred Dataset\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>] 13333/13333, 29.0 task/s, elapsed: 460s, ETA:     0s\n",
      "Saving json data to background_hood_fbumper\\eval_results_blurred.json\n",
      "Add total Change and improvement of original over blurred\n",
      "Saving evaluation results to background_hood_fbumper\\evalBlurred.xlsx\n",
      "Removing temporary filtered annotation file background_hood_fbumper\\annfile_filtered.txt\n"
     ]
    }
   ],
   "source": [
    "evaluate_effectiveness.evaluate_blurred(imgRoot=imgRootValOriginal, classifierConfig=configCAMResOG, \n",
    "                                        classifierCheckpoint=checkpointCAMResOG, annfile=annfileValOriginal,\n",
    "                                        segData=segDataPathNoScaleOG, segConfig=configSeg, saveImgs=True,\n",
    "                                        segCheckpoint=checkpointSeg,  saveDir='background_hood_fbumper', \n",
    "                                        blurredSegments=['front_bumper','hood','background'],\n",
    "                                        eval_data_original='./eval_results_original.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79dfe765",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_segs.main([imgRootValStandford, configSeg, checkpointSeg,\n",
    "                    '-s', 'G:/XAI-Vehicle-Classification/preGenData/Segmentations/StanfordCars_Original/valAllSegsNoScale'])\n",
    "# With pipeline\n",
    "generate_segs.main([imgRootValStandford, configSeg, checkpointSeg, '-p', 'post', configCAMResOG,\n",
    "                    '-s', 'G:/XAI-Vehicle-Classification/preGenData/Segmentations/StanfordCars_Original/valAllSegs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fddf8d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate Results for file: cat_dog.jpg\n",
      "Method for CAM generation: gradcam, eigen-smooth:False, aug-smooth:False, vit-like:False\n",
      "Generate Results for specified files\n",
      "Automatically choose the last norm layer as target_layer.\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 1/1, 3.1 task/s, elapsed: 0s, ETA:     0s\n",
      "Generate Results for file: cat_dog.jpg\n",
      "Method for CAM generation: gradcam, eigen-smooth:False, aug-smooth:False, vit-like:False\n",
      "Generate Results for specified files\n",
      "Automatically choose the last norm layer as target_layer.\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 1/1, 3.0 task/s, elapsed: 0s, ETA:     0s\n"
     ]
    }
   ],
   "source": [
    "cfgPath = 'C:/Users/Linus/Desktop/mmclassification/configs/resnet/resnet50_8xb32_in1k.py'\n",
    "checkpointPath = 'C:/Users/Linus/Desktop/mmclassification/configs/resnet/resnet50_8xb32_in1k_20210831-ea4938fc.pth'\n",
    "d = generate_cams.main(['cat_dog.jpg', cfgPath, checkpointPath, '-r', 'example_dog', '--method', 'gradcam'])\n",
    "c = generate_cams.main(['cat_dog.jpg', cfgPath, checkpointPath, '-r', 'example_dog', '--method', 'gradcam', '--target-category', '284'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f2d7dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method for CAM generation: eigencam2nd, eigen-smooth:False, aug-smooth:False, vit-like:True\n",
      "Generate Results for specified files\n",
      "Automatically choose the last norm layer as target_layer.\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>] 13333/13333, 14.6 task/s, elapsed: 915s, ETA:     0s\n",
      "Save Split file for Cams\n",
      "Creating annotation file at ./output/CAMVisuals.txt\n",
      "Save generated CAMs to ./output/CAMVisuals.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Linus\\Desktop\\XAI-Vehicle-Classification\\scripts\\utils\\io.py:108: UserWarning: Using generate_split_files will redirect the call to generate_ann_file. Consider directly calling that function\n",
      "  warnings.warn(\"Using generate_split_files will redirect the call to generate_ann_file. Consider directly calling that function\")\n"
     ]
    }
   ],
   "source": [
    "generate_cams.main([imgRootValOriginal, configCAMSwinSmallOriginal, checkpointCAMSwinSmallOriginal, \n",
    "                    '-s', 'CAMVisuals', '--method', 'eigencam2nd', '--device', 'cuda', '--vit-like'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34aa7835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>] 13333/13333, 227.4 task/s, elapsed: 59s, ETA:     0s\n"
     ]
    }
   ],
   "source": [
    "generate_cams.saveImgsFromFile('./output/CAMVisuals.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5104421c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
