{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6293ab3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import mmcv\n",
    "import importlib\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from mmcv import Config\n",
    "from mmcls.datasets.pipelines import Compose\n",
    "from mmcls.models.builder import build_classifier\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib import cm\n",
    "from PIL import Image\n",
    "import heapq\n",
    "from mmseg.apis import inference_segmentor, init_segmentor\n",
    "from mmseg.core.evaluation import get_palette\n",
    "from mmseg.datasets.builder import build_dataset, build_dataloader, DATASETS\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "import cv2\n",
    "import pandas\n",
    "import json\n",
    "\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "\n",
    "from scripts import generate_statistics_single\n",
    "from scripts import visualization_seg_masks\n",
    "from scripts import generate_statistics\n",
    "from scripts import generate_cams\n",
    "from scripts import utils\n",
    "from scripts.utils.pipeline import get_pipeline_torchvision\n",
    "from scripts import generate_segs\n",
    "from scripts import visualize_cam_results\n",
    "from scripts.utils.BlurDataset import get_blurred_dataset\n",
    "from scripts.utils import preprocessing, io\n",
    "from scripts.utils.model import get_wrongly_classified\n",
    "from scripts.utils.evaluation import compare_original_blurred\n",
    "from scripts import evaluate_effectiveness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90766d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "configSeg = '../segmentation/ocrnet_hr48_512x512_carparts_noflip/ocrnet_hr48_512x512_carparts_noflip.py'\n",
    "checkpointSeg = '../segmentation/ocrnet_hr48_512x512_carparts_noflip/latest.pth'\n",
    "imgRootTrain = '../data/CompCars_sv_original_split/train'\n",
    "imgRootVal = '../data/CompCars_sv_original_split/val'\n",
    "configCAMResOG = '../CAMModels/resnet/compCars_Original/resnet50_b128x2_compcars-original-split.py'\n",
    "checkpointCAMResOG = '../CAMModels/resnet/compCars_Original/latest.pth'\n",
    "configCAMSwinSmallOG = '../CAMModels/swinSmall/compCars_Original/swin-small_b128x2_compcars-original-split.py'\n",
    "checkpointCAMSwinSmallOG = '../CAMModels/swinSmall/compCars_Original/latest.pth'\n",
    "annfileTrain = '../annfileTrain.txt'\n",
    "annfileVal = '../annfileVal.txt'\n",
    "annfileValGt = '../annfileValGt.txt'\n",
    "imgNameTrain='Acura_Acura_ILX_2a6cce617fc27d.jpg'\n",
    "imgNameVal = 'Acura_Acura_ILX_3c11ef9e42931b.jpg'\n",
    "imgPathTrain=os.path.join(imgRootTrain, imgNameTrain)\n",
    "imgPathVal=os.path.join(imgRootVal, imgNameVal)\n",
    "\n",
    "imgRootValOriginal = '../data/CompCars_sv_original_split/val'\n",
    "imgRootValColor = '../data/CompCars_sv_color_split/val'\n",
    "imgRootValWeb = '../data/CompCars_web_original_split/val'\n",
    "\n",
    "annfileValOriginal = '../data/CompCars_sv_original_split/meta/val.txt'\n",
    "annfileValColor = '../data/CompCars_sv_color_split/meta/val.txt'\n",
    "annfileValWeb = '../data/CompCars_web_original_split/meta/val.txt'\n",
    "\n",
    "paletteName='Comp_Original_Ocrnet_Carparts_Noflip'\n",
    "\n",
    "segDataPath = 'G:/XAI-Vehicle-Classification/preGenData/Segmentations/CompCars_Original/valAllSegs.npz'\n",
    "segDataPathNoScale = 'G:/XAI-Vehicle-Classification/preGenData/Segmentations/CompCars_Original/valAllSegsNoScale.npz'\n",
    "\n",
    "camDataGradCAM = 'G:/XAI-Vehicle-Classification/preGenData/CompCars_original/ResNet/valAllCAMs.npz'\n",
    "camDataEigenCAM = 'G:/XAI-Vehicle-Classification/preGenData/CompCars_original/ResNet/valAllCAMsEigen.npz'\n",
    "camDataEigenGrad = 'G:/XAI-Vehicle-Classification/preGenData/CompCars_original/ResNet/valAllCAMsEigenGrad.npz'\n",
    "camDataGradCAMGPU = 'G:/XAI-Vehicle-Classification/preGenData/CompCars_original/ResNet/valAllCAMsGPU.npz'\n",
    "camDataGradCAMPlusPlus = 'G:/XAI-Vehicle-Classification/preGenData/CompCars_original/ResNet/valAllCAMsGrad++.npz'\n",
    "camDataLayerCAM = 'G:/XAI-Vehicle-Classification/preGenData/CompCars_original/ResNet/valAllCAMsLayer.npz'\n",
    "camDataXCAM = 'G:/XAI-Vehicle-Classification/preGenData/CompCars_original/ResNet/valAllCAMsXGrad.npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7337cc8d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating original model vs blurred background.\n",
      "Evaluating original model vs blurred where segments background are blurred.\n",
      "Created filtered annotation file at compareResults/newLoad\\annfile_filtered.txt\n",
      "Using standard dataset on blurred data at directory ../data/CompCars_sv_original_split/blurred/blurredBackground\n",
      "Model already on GPU\n",
      "Using given evaluation data of original model.\n",
      "Loading data from Json ./eval_results_original.json\n",
      "Computing Evaluation Metrics for Blurred Dataset\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>] 13333/13333, 267.7 task/s, elapsed: 50s, ETA:     0s\n",
      "Saving json data to compareResults/newLoad\\eval_results_blurred.json\n",
      "Add total Change and improvement of original over blurred\n",
      "Saving evaluation results to compareResults/newLoad\\evalBlurred.xlsx\n",
      "Removing temporary filtered annotation file compareResults/newLoad\\annfile_filtered.txt\n"
     ]
    }
   ],
   "source": [
    "imgRootBlurredBackground = '../data/CompCars_sv_original_split/blurred/blurredBackground'\n",
    "evaluate_effectiveness.evaluate_blurred_background(imgRoot=imgRootValOriginal, classifierConfig=configCAMResOG, \n",
    "                                                   classifierCheckpoint=checkpointCAMResOG, annfile=annfileValOriginal,\n",
    "                                                   segData=segDataPathNoScale, segConfig=configSeg, saveImgs=False,\n",
    "                                                   segCheckpoint=checkpointSeg,  saveDir='compareResults/newLoad',\n",
    "                                                   eval_data_original='./eval_results_original.json',\n",
    "                                                   imgRootBlurred=imgRootBlurredBackground)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e32176c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
